{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..')) # include top level package in python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from comparison.examples.vae_mnist import VAE_MNIST\n",
    "from comparison.loss import ELBO, IWAE_loss, CIWAE_loss, PIWAE_loss\n",
    "from comparison.metric import IWAE_64, log_px\n",
    "from comparison.metric import IWAE_metric, CIWAE_metric, PIWAE_metric\n",
    "from tqdm.notebook import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e561804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change device as needed. \n",
    "# CPU is supported on all machines, CUDA for specific GPUs.\n",
    "\n",
    "# device = 'cpu'\n",
    "device = 'cuda'\n",
    "\n",
    "import time\n",
    "model_dir = './_modeldata/'\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = datasets.MNIST('./_mnist', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n",
    "test_dataset = datasets.MNIST('./_mnist', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# We set a low batch_size for sampling IWAE with K=5000\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ca4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optims, dataloader, loss_function, label,):\n",
    "    model.train()\n",
    "    \n",
    "    for imgs, _ in tqdm(dataloader, desc=\"Training Epoch №%s\" % label, leave=False):\n",
    "        imgs = imgs.view(-1, 28*28).to(device)\n",
    "        losses = loss_function(model, imgs)\n",
    "        #convert single values to tuple for uniformity\n",
    "        if type(losses) is not tuple:\n",
    "            losses = losses,\n",
    "            \n",
    "        for optim, loss in zip(optims, losses):\n",
    "            loss = -loss\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "    model.train(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is kinda slow and if someone who's better at pytorch\n",
    "# than me fancies speeding it up would be very helpful\n",
    "\n",
    "def test(model, test_loader, label):\n",
    "    with torch.no_grad():\n",
    "        #evaluate metrics\n",
    "        test_scores = {\n",
    "            \"IWAE-64\": 0.0,\n",
    "            \"log(px)\": 0.0,\n",
    "            \"-KL\"    : 0.0\n",
    "        }\n",
    "\n",
    "        for imgs, _ in tqdm(test_loader, desc=\"Test Epoch №%s\" % label, leave=False):\n",
    "            imgs = imgs.view(-1, 28*28).to(device)            \n",
    "            IWAE_64_loss = IWAE_64(model, imgs)\n",
    "            logpx_loss = log_px(model, imgs)\n",
    "            negKL_loss = logpx_loss - IWAE_64_loss\n",
    "            \n",
    "            # I can't work out best practice for summing these tensors\n",
    "            # expecially with cuda maybe it's faster to append them all to a \n",
    "            # list and then sum that but idk\n",
    "            test_scores[\"IWAE-64\"] += IWAE_64_loss.sum().item()\n",
    "            test_scores[\"log(px)\"] += logpx_loss.sum().item()\n",
    "            test_scores[\"-KL\"] += negKL_loss.sum().item()\n",
    "        \n",
    "        N = len(test_dataset)\n",
    "        test_scores[\"IWAE-64\"] /= N\n",
    "        test_scores[\"log(px)\"] /= N\n",
    "        test_scores[\"-KL\"] /= N\n",
    "        \n",
    "        return test_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e820f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_and_results(model, test_metrics, loc, name):\n",
    "    torch.save(model.state_dict(), loc + \"_model_\"+name+\"_\"+timestr )\n",
    "\n",
    "    with open(loc+'_results_'+name+'_'+timestr+'.csv','w') as outfile:   \n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(test_metrics.keys())\n",
    "        writer.writerows(zip(*test_metrics.values()))\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, optims, train_loader, test_loader, loss_function, no_epochs=3, epochs_per_sample = 25, backup_loc=\"\"):    \n",
    "    test_metrics = {\n",
    "        \"epoch\"  : [],\n",
    "        \"IWAE-64\": [],\n",
    "        \"log(px)\": [],\n",
    "        \"-KL\"    : []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, no_epochs + 1):\n",
    "        train_epoch(model, optims, train_loader, loss_function, epoch)\n",
    "        if(epoch % epochs_per_sample == 10 or epoch == no_epochs):\n",
    "            test_scores = test(model, test_loader, epoch)\n",
    "\n",
    "            test_metrics[\"epoch\"].append(epoch)\n",
    "            test_metrics[\"IWAE-64\"].append(test_scores[\"IWAE-64\"])\n",
    "            test_metrics[\"log(px)\"].append(test_scores[\"log(px)\"])\n",
    "            test_metrics[\"-KL\"].append(test_scores[\"-KL\"])\n",
    "        if(epoch % 500 == 1 and backup_loc != \"\"):\n",
    "            write_model_and_results(model, test_metrics, backup_loc, \"epoch\"+str(epoch))\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_MNIST().to(device)\n",
    "lr=1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "inf_optim = torch.optim.Adam(model.encode_params(), lr=lr)\n",
    "gen_optim = torch.optim.Adam(model.decode_params(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06dc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch №31:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch №32:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch №33:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121c55b3c145477d96cf7ebc60d36e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch №34:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_discard(loss_fn, M=1, K=1):\n",
    "    return lambda model, xs: loss_fn(model(xs, M, K))\n",
    "\n",
    "class LossTest:\n",
    "    \n",
    "    def __init__(self, name, loss_fn, optims, no_epochs, epochs_per_sample, no_runs = 1):\n",
    "        self.name = name\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optims = optims\n",
    "        self.no_epochs = no_epochs\n",
    "        self.epochs_per_sample = epochs_per_sample\n",
    "        self.no_runs = no_runs\n",
    "\n",
    "        \n",
    "fig5_tests = [\n",
    "    LossTest(\"IWAE\", eval_discard(IWAE_loss, M=1, K=64), [optim], 3500, 25, 1),\n",
    "    LossTest(\"CIWAE_5\", eval_discard(CIWAE_loss, M=1, K=64), [optim], 3500, 25, 1),\n",
    "    LossTest(\"PIWAE8_8\", eval_discard(PIWAE_loss, M=8, K=8), [inf_optim, gen_optim], 3500, 25, 1),\n",
    "    LossTest(\"MIWAE8_8\", eval_discard(IWAE_loss, M=8, K=8), [optim], 3500, 25, 1),\n",
    "    LossTest(\"VAE\", eval_discard(IWAE_loss, M=64, K=1), [optim], 3500, 25, 1)\n",
    "]        \n",
    "\n",
    "#iwae64_results = train_and_evaluate(model, [optim], train_loader, test_loader, iwae64, no_epochs=1)\n",
    "#iwae05_results = train_and_evaluate(model, [optim], train_loader, test_loader, ciwae05, no_epochs=5)\n",
    "\n",
    "\n",
    "for t in fig5_tests:\n",
    "    print(\"Training \", t.name)\n",
    "    for run in range(1, t.no_runs+1):\n",
    "        print(\"Run \", run)\n",
    "        model = VAE_MNIST().to(device)\n",
    "        loc = model_dir + t.name + \"_run\" + str(run) \n",
    "        test_results = train_and_evaluate(model, t.optims, train_loader, test_loader, t.loss_fn, t.no_epochs, t.epochs_per_sample, loc)\n",
    "        \n",
    "        write_model_and_results(model, test_results, loc, \"final\")\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparison.plot import plot_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smoothed(-losses, sigma=10, fit_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd375bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_ess(model, T=100):\n",
    "    effective_sample_sizes = []\n",
    "\n",
    "    for imgs, _ in test_loader:\n",
    "        with torch.no_grad():\n",
    "            imgs = imgs.view(-1, 28*28).to(device)\n",
    "            esss = sample_ess(model, imgs, T=100)\n",
    "\n",
    "            for ess in list(esss):\n",
    "                effective_sample_sizes.append(ess.item())\n",
    "    return effective_sample_sizes\n",
    "\n",
    "effective_sample_sizes = compute_ess(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793db1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure instance\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.violinplot([effective_sample_sizes, [1e-2], [2e-2]])\n",
    "plt.ylim(0,8e-2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6195daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,26))\n",
    "\n",
    "for imgs, _ in tqdm(test_loader):\n",
    "    for i in range(imgs.shape[0]):\n",
    "        if i >= 10:\n",
    "            break\n",
    "        img = imgs[i].view(28 * 28).to(device)\n",
    "        recon = model.reconstruct(img)\n",
    "        ax = plt.subplot(10, 2, 2 * i + 1)\n",
    "        ax.imshow(img.view(28, 28).clone().detach().cpu())\n",
    "        plt.title(\"Original\")\n",
    "        ax = plt.subplot(10, 2, 2 * i + 2)\n",
    "        ax.imshow(recon.view(28, 28).clone().detach().cpu())\n",
    "        plt.title(\"Reconstructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8debd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

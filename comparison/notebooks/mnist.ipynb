{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..')) # include top level package in python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from comparison.examples.mnist.vae_mnist import VAE_MNIST\n",
    "# from comparison.loss import ELBO, IWAE\n",
    "from comparison.metric import IWAE_64, log_px\n",
    "from comparison.metric import IWAE_metric, CIWAE_metric, PIWAE_metric\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change device as needed. \n",
    "# CPU is supported on all machines, CUDA for specific GPUs.\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = datasets.MNIST('./_mnist', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n",
    "test_dataset = datasets.MNIST('./_mnist', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optim, dataloader, loss_function, label):\n",
    "    model.train()\n",
    "    \n",
    "    for imgs, _ in tqdm(dataloader, desc=\"Training Epoch №%s\" % label, leave=False):\n",
    "        imgs = imgs.view(-1, 28*28).to(device)\n",
    "        loss = -loss_function(model, imgs)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8cd90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is kinda slow and if someone who's better at pytorch\n",
    "# than me fancies speeding it up would be very helpful\n",
    "\n",
    "def test(model, test_loader, label):\n",
    "    with torch.no_grad():\n",
    "        #evaluate metrics\n",
    "        test_scores = {\n",
    "            \"IWAE-64\": 0.0,\n",
    "            \"log(px)\": 0.0,\n",
    "            \"-KL\"    : 0.0\n",
    "        }\n",
    "\n",
    "        for imgs, _ in tqdm(test_loader, desc=\"Test Epoch №%s\" % label, leave=False):\n",
    "            imgs = imgs.view(-1, 28*28).to(device)            \n",
    "            IWAE_64_loss = IWAE_64(model, imgs)\n",
    "            logpx_loss = log_px(model, imgs)\n",
    "            negKL_loss = logpx_loss - IWAE_64_loss\n",
    "            \n",
    "            # I can't work out best practice for summing these tensors\n",
    "            # expecially with cuda maybe it's faster to append them all to a \n",
    "            # list and then sum that but idk\n",
    "            test_scores[\"IWAE-64\"] += IWAE_64_loss.sum().item()\n",
    "            test_scores[\"log(px)\"] += logpx_loss.sum().item()\n",
    "            test_scores[\"-KL\"] += negKL_loss.sum().item()\n",
    "        \n",
    "        return test_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e820f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, optim, train_loader, test_loader, loss_function, no_epochs=3):\n",
    "    model.train()\n",
    "    \n",
    "    test_metrics = {\n",
    "        \"IWAE-64\": [],\n",
    "        \"log(px)\": [],\n",
    "        \"-KL\"    : []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, no_epochs + 1):\n",
    "        train_epoch(model, optim, train_loader, loss_function, epoch)\n",
    "        test_scores = test(model, test_loader, epoch)\n",
    "\n",
    "        test_metrics[\"IWAE-64\"].append(test_scores[\"IWAE-64\"])\n",
    "        test_metrics[\"log(px)\"].append(test_scores[\"log(px)\"])\n",
    "        test_metrics[\"-KL\"].append(test_scores[\"-KL\"])\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_MNIST().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2753d98dd14c369a3c2850b412848e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch №1:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6790cab51b1645ae8dd42f0550cb9588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch №1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38652.7188)\n",
      "tensor(36829.7617)\n",
      "tensor(34817.4219)\n",
      "tensor(38157.1602)\n",
      "tensor(34745.5430)\n",
      "tensor(33560.7773)\n"
     ]
    }
   ],
   "source": [
    "iwae64  = lambda model, xs: IWAE_metric(model, xs, M=1, K=64)\n",
    "ciwae05 = lambda model, xs: CIWAE_metric(model, xs, beta=0.5)\n",
    "#etc etc\n",
    "\n",
    "iwae64_results = train_and_evaluate(model, optim, train_loader, test_loader, iwae64, no_epochs=1)\n",
    "#ciwae05_results = train_and_evaluate(model, optim, train_loader, test_loader, ciwae05, no_epochs=1)\n",
    "\n",
    "print(iwae64_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparison.plot import plot_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smoothed(-losses, sigma=10, fit_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,26))\n",
    "\n",
    "for imgs, _ in test_loader:\n",
    "    for i in range(imgs.shape[0]):\n",
    "        if i >= 10:\n",
    "            break\n",
    "        img = imgs[i].view(28 * 28).to(device)\n",
    "        recon = model.reconstruct(img)\n",
    "        ax = plt.subplot(10, 2, 2 * i + 1)\n",
    "        ax.imshow(img.view(28, 28).clone().detach().cpu())\n",
    "        plt.title(\"Original\")\n",
    "        ax = plt.subplot(10, 2, 2 * i + 2)\n",
    "        ax.imshow(recon.view(28, 28).clone().detach().cpu())\n",
    "        plt.title(\"Reconstructed\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
